{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6toho7uRO7v"
      },
      "source": [
        "# Question 1\n",
        "## Developing an Artificial Neural Network from Scratch.\n",
        "\n",
        "In this notebook, we will be developing a fully connected feedforward neural network.\n",
        "\n",
        "We will import the MNIST dataset from keras datsets. The MNIST dataset contains images of 28x28 pixels each having values ranging from 0-255.\n",
        "It has 60000 images in the training set and 10000 images in the test set. However, we will only use the first 10000 images for training and first 1000 images for testing because our code isn't optimized and it takes time to run. We are not looking for accuracy of our network right now, we will be doing that in the next question when we will be implementing the same using Tensorflow.\n",
        "\n",
        "\n",
        "Run the first 3 cells. Your code begins after that."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "nI17X78rktdA"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from keras.datasets import mnist\n",
        "import random"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrINntzulT4M",
        "outputId": "72879853-cec4-4d1e-dd27-245e969cd0b6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 0us/step\n",
            "(60000, 28, 28)\n",
            "(60000,)\n",
            "(10000, 28, 28)\n",
            "(10000,)\n"
          ]
        }
      ],
      "source": [
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "print(train_X.shape)\n",
        "print(train_y.shape)\n",
        "print(test_X.shape)\n",
        "print(test_y.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dr4rLzb9ZBQE"
      },
      "source": [
        "As discussed in the class, the images are flattened to a column.\n",
        "\n",
        "Then we are normalizing them by dividing by 255."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "0jy7CLWCEwfn"
      },
      "outputs": [],
      "source": [
        "train_X=train_X.reshape(60000,784,1)    # flattening\n",
        "test_X=test_X.reshape(10000,784,1)\n",
        "\n",
        "train_y=train_y.reshape(60000,1)\n",
        "test_y=test_y.reshape(10000,1)\n",
        "\n",
        "train_X= train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "train_X=train_X[:10000]         #taking the first 10000 images.\n",
        "train_y=train_y[:10000]\n",
        "test_X=test_X[:1000]\n",
        "test_y=test_y[:1000]\n",
        "train_data=list(zip(train_X,train_y))\n",
        "test_data=list(zip(test_X,test_y))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wWwDzh6kZOy3"
      },
      "source": [
        "## 1.1 Write the code for Sigmoid Function."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "7Q5a8tGYku-7"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  return 1/(1+np.exp(-z))\n",
        "\n",
        "def sigmoid_prime(z):\n",
        "    \"\"\"Derivative of the sigmoid function.\"\"\"\n",
        "    return sigmoid(z) * (1 - sigmoid(z))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIJI5SoxbJaq"
      },
      "source": [
        "## 1.2 The Network\n",
        "\n",
        "We will making a class called Network which has certain functions inside it. The cost function used is Cross-Entropy Loss. You need to code only the first 3. Rest are done for you.  There are various places within the code marked as stop_zone. Read the instructions below the code at those places to check whether your code till there is correct or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "RwsydmyTEt0z"
      },
      "outputs": [],
      "source": [
        "class Network(object):\n",
        "    def __init__(self, sizes): # sizes is a list containing the network.\n",
        "                              # eg : [784,128,10] means input =784 neurons,\n",
        "                              #    1st hidden layer 128 neurons, output 10 neurons.\n",
        "        self.sizes = sizes\n",
        "        self.num_layers = len(sizes) # ...can you say the number of layers based on the list called sizes...\n",
        "        self.weights = [np.random.randn(x, y) for x, y in zip(sizes[1:], sizes[:-1])]\n",
        "        self.biases = [np.random.randn(x, 1) for x in sizes[1:]] # ...can you do this by understanding the self.weights...\n",
        "\n",
        "    def show(self):\n",
        "        print(self.num_layers)\n",
        "        for bias in self.biases:\n",
        "            print(bias.shape)\n",
        "        for weight in self.weights:\n",
        "            print(weight.shape)\n",
        "\n",
        "    def forwardpropagation(self, a):\n",
        "        for b, w in zip(self.biases, self.weights):\n",
        "            a = sigmoid(np.dot(w, a) + b) # a is activation... # sig (w.a +b)\n",
        "            print(a.shape)\n",
        "        return a\n",
        "\n",
        "    def backpropagation(self, x, y):\n",
        "\n",
        "        # nothing to do in this 3 lines. it is for creating a one-hot encoded vector of the labels.\n",
        "        y_t = np.zeros((len(y), 10))\n",
        "        y_t[np.arange(len(y)), y] = 1\n",
        "        y_t = y_t.T\n",
        "\n",
        "        # nabla_b=dC/db and nabla_w=dC/dw. They are lists of shapes equal to that of bias and weights.\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "\n",
        "        # initially, a0 = input.\n",
        "        activation = x\n",
        "        activation_list = [x]\n",
        "\n",
        "        # step 1 : calculation of delta in last layer\n",
        "\n",
        "        # write the same forward propagation code here but while doing so store the a's.\n",
        "        for w, b in zip(self.weights, self.biases):\n",
        "            activation = sigmoid(np.dot(w, activation) + b) # just written above...\n",
        "            activation_list.append(activation)\n",
        "\n",
        "        delta = (activation_list[-1] - y_t) * sigmoid_prime(np.dot(self.weights[-1], activation_list[-2]) + self.biases[-1]) # delta is dC/dz3... how is it calculated?...\n",
        "\n",
        "        # step 2 : nabla_b and nabla_w relation with delta of last layer\n",
        "\n",
        "        nabla_b[-1] = delta # how is dC/db3 and dC/dz3 related...\n",
        "        nabla_w[-1] = np.dot(delta, activation_list[-2].T) # how is dC/dw3 and dC/dz3 related...\n",
        "\n",
        "        # print(\"{} {}\".format(nabla_b[-1].shape, nabla_w[-1].shape) )\n",
        "        #stop_zone 3 : remove comment from the print statement just above and run the cell for stop_zone3.\n",
        "        # don't forget commenting out.\n",
        "\n",
        "        # step 3 : calculation of delta for hidden layers\n",
        "\n",
        "        for j in range(2, self.num_layers):\n",
        "            z = np.dot(self.weights[-j], activation_list[-j-1]) + self.biases[-j]\n",
        "            sig_der = sigmoid_prime(z)\n",
        "            delta = np.dot(self.weights[-j+1].T, delta) * sig_der # how is dC/dz2 and dC/dz3 related ? Look i have calculated one term already for you (sig_der)...\n",
        "\n",
        "            # step 4 : nabla_b and nabla_w relation with delta of others layers\n",
        "            nabla_b[-j] = delta # again, how is dC/db2 and dC/dz2 related...\n",
        "            nabla_w[-j] = np.dot(delta, activation_list[-j-1].T) # how is dC/dw2 and dC/dz2 related...\n",
        "\n",
        "        return (nabla_b, nabla_w)\n",
        "\n",
        "    def SGD(self, train_data, epochs, mini_batch_size, lr):\n",
        "        n_train = len(train_data)\n",
        "        for i in range(epochs):\n",
        "            random.shuffle(train_data)\n",
        "            mini_batches = [\n",
        "                train_data[k:k + mini_batch_size]\n",
        "                for k in range(0, n_train, mini_batch_size)\n",
        "            ] # ...Split the data into batches each of size = mini_batch_size  ...\n",
        "\n",
        "            # print(np.array(mini_batches, dtype=object).shape)\n",
        "\n",
        "            for mini_batch in mini_batches:\n",
        "                self.update_mini_batch(mini_batch, lr)\n",
        "\n",
        "            self.predict(train_data)\n",
        "            print(\"Epoch {0} completed.\".format(i+1))\n",
        "\n",
        "    # the functions below are complete. If you are fine till stop_zone 5, you can run\n",
        "    # this whole cell and train, test the data by running the last cell of the notebook.\n",
        "    # You may need to wait for around 10 minutes to see the test predictions.\n",
        "\n",
        "    def update_mini_batch(self, mini_batch, lr):\n",
        "        nabla_b = [np.zeros(b.shape) for b in self.biases]\n",
        "        nabla_w = [np.zeros(w.shape) for w in self.weights]\n",
        "        for x, y in mini_batch:\n",
        "            delta_b, delta_w = self.backpropagation(x, y)\n",
        "            nabla_b = [nb + db for nb, db in zip(nabla_b, delta_b)]\n",
        "            nabla_w = [nw + dw for nw, dw in zip(nabla_w, delta_w)]\n",
        "        self.weights = [w - lr * nw / len(mini_batch) for w, nw in zip(self.weights, nabla_w)]\n",
        "        self.biases = [b - lr * nb / len(mini_batch) for b, nb in zip(self.biases, nabla_b)]\n",
        "\n",
        "    def predict(self, test_data):\n",
        "        test_results = [(np.argmax(self.forwardpropagation(x)), y) for x, y in test_data]\n",
        "        # returns the index of that output neuron which has highest activation\n",
        "\n",
        "        num = sum(int(x == y) for x, y in test_results)\n",
        "        print(\"{0}/{1} classified correctly.\".format(num, len(test_data)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "8u8cVnGamVgP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "4\n",
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n",
            "(128, 784)\n",
            "(64, 128)\n",
            "(10, 64)\n"
          ]
        }
      ],
      "source": [
        "# stop_zone 1\n",
        "# def show(self):\n",
        "#       print(self.num_layers)\n",
        "#       for bias in self.biases:\n",
        "#         print(bias.shape)\n",
        "#       for weight in self.weights:\n",
        "#         print(weight.shape)\n",
        "# Copy this show function from here. Paste it inside that Network Class.\n",
        "# Comment out the show function here. Run this cell.\n",
        "\n",
        "net=Network([784,128,64,10])\n",
        "net.show()\n",
        "\n",
        "# The desired output is :\n",
        "# 4\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "# (128, 784)\n",
        "# (64, 128)\n",
        "# (10, 64)\n",
        "#  If you are getting this, you are correct. Proceed to forwardpropagation.\n",
        "\n",
        "# Keeping the show function over there in the Network class doesn't make any\n",
        "# difference. You may delete it if you wish. Better toss a coin."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "D7EJBF7XsSft"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n"
          ]
        }
      ],
      "source": [
        "# stop_zone 2\n",
        "# to use this, make sure your data is loaded. Run this cell.\n",
        "net=Network([784,128,64,10])\n",
        "output = net.forwardpropagation(train_X[0])\n",
        "\n",
        "# The desired output is :\n",
        "# (784, 1)\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "#  If you are getting this, you are correct. Proceed to forwardpropagation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "FwHWyaKNhIIk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(10, 1) (10, 64)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "([array([[ 6.66268720e-07],\n",
              "         [ 1.73439085e-03],\n",
              "         [ 5.29377125e-08],\n",
              "         [-1.00264616e-07],\n",
              "         [ 2.51171103e-09],\n",
              "         [-4.49262968e-03],\n",
              "         [-2.52557377e-06],\n",
              "         [ 8.28272884e-05],\n",
              "         [-5.78680702e-10],\n",
              "         [-1.01526523e-02],\n",
              "         [-1.02913252e-08],\n",
              "         [-1.51546780e-02],\n",
              "         [-7.01362296e-03],\n",
              "         [ 4.28237212e-03],\n",
              "         [-1.25081406e-05],\n",
              "         [-8.64807324e-09],\n",
              "         [-3.85702552e-03],\n",
              "         [ 2.71862859e-07],\n",
              "         [-1.54866674e-02],\n",
              "         [-1.81654375e-02],\n",
              "         [-6.08138118e-06],\n",
              "         [-1.88398997e-02],\n",
              "         [-2.87650978e-04],\n",
              "         [ 1.11205564e-08],\n",
              "         [-1.23921915e-07],\n",
              "         [-1.45327408e-07],\n",
              "         [ 1.09362569e-03],\n",
              "         [ 3.84600711e-03],\n",
              "         [ 8.15647457e-07],\n",
              "         [ 6.64603413e-06],\n",
              "         [-4.42441003e-04],\n",
              "         [-8.42768419e-13],\n",
              "         [-7.75387956e-09],\n",
              "         [ 1.92032592e-02],\n",
              "         [ 2.12280226e-03],\n",
              "         [-2.11681340e-08],\n",
              "         [ 5.50952353e-04],\n",
              "         [ 2.23418222e-10],\n",
              "         [ 1.84619738e-07],\n",
              "         [ 1.96357731e-04],\n",
              "         [-1.04572380e-09],\n",
              "         [-1.51772490e-10],\n",
              "         [ 2.79506127e-05],\n",
              "         [-1.91484967e-05],\n",
              "         [ 6.23541862e-08],\n",
              "         [-2.07555150e-10],\n",
              "         [ 2.67032376e-05],\n",
              "         [ 1.92405854e-04],\n",
              "         [-4.31079806e-04],\n",
              "         [-1.35161277e-05],\n",
              "         [ 6.05194594e-03],\n",
              "         [ 5.15885177e-08],\n",
              "         [-3.70559063e-05],\n",
              "         [ 2.40801267e-02],\n",
              "         [-3.92429057e-03],\n",
              "         [ 3.74077074e-03],\n",
              "         [ 1.49018702e-08],\n",
              "         [ 5.94043997e-03],\n",
              "         [ 1.66652451e-03],\n",
              "         [-4.53165466e-06],\n",
              "         [-3.77125947e-04],\n",
              "         [-1.65159128e-02],\n",
              "         [-5.59021740e-10],\n",
              "         [ 1.10813854e-03],\n",
              "         [ 1.95173645e-02],\n",
              "         [-5.05889578e-07],\n",
              "         [ 1.88735653e-07],\n",
              "         [-7.73966391e-06],\n",
              "         [-5.33584497e-10],\n",
              "         [ 1.05382309e-07],\n",
              "         [-3.05762097e-06],\n",
              "         [ 3.20742382e-05],\n",
              "         [ 1.76057899e-02],\n",
              "         [ 2.63142866e-07],\n",
              "         [-5.31554033e-08],\n",
              "         [-3.64524343e-05],\n",
              "         [-8.47657950e-06],\n",
              "         [ 1.39861828e-06],\n",
              "         [ 1.95117246e-12],\n",
              "         [ 5.77448025e-07],\n",
              "         [ 1.90810902e-06],\n",
              "         [-3.12291141e-09],\n",
              "         [-5.73539801e-03],\n",
              "         [ 8.07402619e-05],\n",
              "         [ 3.17654415e-04],\n",
              "         [ 1.52843056e-02],\n",
              "         [ 9.28812450e-04],\n",
              "         [-2.47215230e-10],\n",
              "         [ 6.09188136e-09],\n",
              "         [-8.91032631e-11],\n",
              "         [ 1.04448425e-04],\n",
              "         [-2.46501160e-03],\n",
              "         [-5.81006478e-08],\n",
              "         [-1.28704387e-04],\n",
              "         [-6.79641565e-03],\n",
              "         [ 4.39955908e-05],\n",
              "         [ 1.48655740e-03],\n",
              "         [ 7.34874005e-04],\n",
              "         [ 6.80110503e-07],\n",
              "         [ 5.14332816e-07],\n",
              "         [ 8.02136163e-04],\n",
              "         [ 1.16953150e-02],\n",
              "         [-3.26963485e-05],\n",
              "         [ 5.86578352e-10],\n",
              "         [-2.15550283e-03],\n",
              "         [-5.49015160e-05],\n",
              "         [-3.64340541e-03],\n",
              "         [-2.09374047e-06],\n",
              "         [-4.49075959e-03],\n",
              "         [ 4.15808453e-04],\n",
              "         [-2.02248346e-04],\n",
              "         [ 1.56226925e-03],\n",
              "         [-4.69951764e-03],\n",
              "         [-7.30545785e-08],\n",
              "         [-1.05846512e-02],\n",
              "         [ 3.24656356e-10],\n",
              "         [ 9.91695308e-05],\n",
              "         [-1.50684729e-06],\n",
              "         [-1.36456298e-03],\n",
              "         [ 6.77059169e-08],\n",
              "         [ 3.33385084e-06],\n",
              "         [-1.35372894e-03],\n",
              "         [-5.12949316e-09],\n",
              "         [ 1.02703384e-05],\n",
              "         [-5.99354843e-03],\n",
              "         [-7.69462227e-05],\n",
              "         [-4.70173979e-03],\n",
              "         [-2.29431153e-07]]),\n",
              "  array([[-2.56989811e-05],\n",
              "         [-1.00957881e-02],\n",
              "         [-9.91817774e-07],\n",
              "         [-2.11682700e-07],\n",
              "         [ 2.05801004e-04],\n",
              "         [ 1.97297244e-06],\n",
              "         [-2.47592415e-03],\n",
              "         [ 2.63444866e-03],\n",
              "         [ 3.27311127e-04],\n",
              "         [-1.73597118e-04],\n",
              "         [ 2.95267360e-04],\n",
              "         [-1.46140021e-05],\n",
              "         [ 9.38588160e-03],\n",
              "         [ 2.73164336e-02],\n",
              "         [-2.93937477e-02],\n",
              "         [ 2.53599135e-04],\n",
              "         [-5.71968634e-11],\n",
              "         [ 1.38820167e-04],\n",
              "         [-7.74379712e-05],\n",
              "         [-2.88540842e-06],\n",
              "         [-1.47975028e-06],\n",
              "         [ 3.76438907e-06],\n",
              "         [ 7.61517807e-07],\n",
              "         [-3.83280139e-03],\n",
              "         [-1.35432859e-05],\n",
              "         [ 2.27335957e-03],\n",
              "         [-2.10848278e-04],\n",
              "         [-2.73106662e-02],\n",
              "         [-4.90128851e-04],\n",
              "         [ 9.99781055e-05],\n",
              "         [-1.08759670e-04],\n",
              "         [ 1.43767256e-05],\n",
              "         [-1.14798812e-04],\n",
              "         [-2.51643555e-03],\n",
              "         [-4.74649137e-04],\n",
              "         [-3.64693461e-05],\n",
              "         [ 7.67645371e-06],\n",
              "         [ 1.08536191e-04],\n",
              "         [-3.12322171e-07],\n",
              "         [-4.51571191e-05],\n",
              "         [ 7.72313868e-03],\n",
              "         [ 2.29476913e-05],\n",
              "         [ 2.32140742e-03],\n",
              "         [-1.72718679e-03],\n",
              "         [-4.73639626e-05],\n",
              "         [ 4.45817002e-03],\n",
              "         [-1.56914274e-07],\n",
              "         [-5.98673909e-07],\n",
              "         [ 7.40660758e-04],\n",
              "         [-5.36393276e-02],\n",
              "         [-6.96820169e-03],\n",
              "         [ 3.80602920e-04],\n",
              "         [ 1.82764745e-02],\n",
              "         [-5.49727500e-04],\n",
              "         [-1.71930154e-06],\n",
              "         [-4.19529531e-02],\n",
              "         [-5.80888162e-05],\n",
              "         [-7.26467152e-07],\n",
              "         [-1.87454814e-05],\n",
              "         [ 8.71336058e-03],\n",
              "         [ 3.73107520e-03],\n",
              "         [-2.78642041e-03],\n",
              "         [-4.95969735e-06],\n",
              "         [ 2.32818854e-04]]),\n",
              "  array([[ 1.59491636e-05],\n",
              "         [ 1.46023618e-02],\n",
              "         [ 4.81547071e-02],\n",
              "         [ 6.39871555e-05],\n",
              "         [ 5.03178955e-03],\n",
              "         [-2.26225709e-03],\n",
              "         [ 6.46886653e-05],\n",
              "         [ 4.87841802e-03],\n",
              "         [ 1.07460609e-01],\n",
              "         [ 1.14722547e-01]])],\n",
              " [array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]),\n",
              "  array([[-2.10118101e-10, -2.35516427e-06, -2.52162905e-11, ...,\n",
              "          -1.45153868e-07, -2.37435021e-05, -4.07693942e-10],\n",
              "         [-8.25444331e-08, -9.25221095e-04, -9.90616418e-09, ...,\n",
              "          -5.70233773e-05, -9.32758250e-03, -1.60161667e-07],\n",
              "         [-8.10922683e-12, -9.08944122e-08, -9.73188975e-13, ...,\n",
              "          -5.60201922e-09, -9.16348679e-07, -1.57344019e-11],\n",
              "         ...,\n",
              "         [-2.27821236e-08, -2.55359454e-04, -2.73408452e-09, ...,\n",
              "          -1.57383555e-05, -2.57439696e-03, -4.42043486e-08],\n",
              "         [-4.05511092e-11, -4.54527825e-07, -4.86654193e-12, ...,\n",
              "          -2.80135330e-08, -4.58230558e-06, -7.86816627e-11],\n",
              "         [ 1.90355622e-09,  2.13365130e-05,  2.28445938e-10, ...,\n",
              "           1.31501545e-06,  2.15103273e-04,  3.69348636e-09]]),\n",
              "  array([[ 1.59454450e-05,  5.91870163e-07,  5.99443301e-10,\n",
              "           1.57489925e-11,  1.59401913e-05,  3.11615005e-10,\n",
              "           1.84304884e-07,  1.56974858e-05,  1.56831720e-05,\n",
              "           1.56063465e-05,  3.30194010e-08,  7.45299091e-09,\n",
              "           4.57723163e-06,  1.37099501e-05,  5.83346040e-06,\n",
              "           4.97074030e-08,  9.30759706e-15,  1.59408869e-05,\n",
              "           7.54870861e-08,  4.22592876e-09,  1.59485676e-05,\n",
              "           1.59487908e-05,  1.59490254e-05,  1.55316776e-05,\n",
              "           1.93476772e-09,  1.18361006e-07,  1.95616273e-07,\n",
              "           1.43103567e-05,  1.59040723e-05,  1.59116376e-05,\n",
              "           1.59380690e-05,  1.59471518e-05,  1.59364002e-05,\n",
              "           1.53603112e-05,  1.57088529e-05,  2.95592347e-09,\n",
              "           1.59484583e-05,  8.64716424e-09,  5.02529566e-10,\n",
              "           1.22301291e-08,  1.55110098e-05,  8.72118103e-09,\n",
              "           3.66032729e-07,  1.58543626e-05,  1.58866049e-05,\n",
              "           3.56789781e-07,  5.20186195e-11,  4.80402401e-11,\n",
              "           7.68160089e-08,  9.73932813e-06,  1.05315499e-05,\n",
              "           1.58856200e-05,  1.18800693e-05,  1.10516456e-05,\n",
              "           3.33868035e-10,  1.87760488e-06,  3.14215718e-08,\n",
              "           1.59490865e-05,  1.59422874e-05,  5.49478703e-06,\n",
              "           4.36453045e-07,  2.17288727e-07,  1.59232124e-05,\n",
              "           1.58981714e-05],\n",
              "         [ 1.45989572e-02,  5.41890629e-04,  5.48824265e-07,\n",
              "           1.44190939e-08,  1.45941472e-02,  2.85301172e-07,\n",
              "           1.68741551e-04,  1.43719366e-02,  1.43588314e-02,\n",
              "           1.42884934e-02,  3.02311302e-05,  6.82363495e-06,\n",
              "           4.19071458e-03,  1.25522352e-02,  5.34086311e-03,\n",
              "           4.55099404e-05,  8.52163183e-12,  1.45947841e-02,\n",
              "           6.91126992e-05,  3.86907692e-06,  1.46018162e-02,\n",
              "           1.46020205e-02,  1.46022353e-02,  1.42201298e-02,\n",
              "           1.77138934e-06,  1.08366199e-04,  1.79097768e-04,\n",
              "           1.31019414e-02,  1.45610782e-02,  1.45680047e-02,\n",
              "           1.45922041e-02,  1.46005200e-02,  1.45906762e-02,\n",
              "           1.40632341e-02,  1.43823438e-02,  2.70631522e-06,\n",
              "           1.46017161e-02,  7.91696821e-06,  4.60094257e-07,\n",
              "           1.11973753e-05,  1.42012072e-02,  7.98473477e-06,\n",
              "           3.35123677e-04,  1.45155662e-02,  1.45450858e-02,\n",
              "           3.26661236e-04,  4.76259899e-08,  4.39835585e-08,\n",
              "           7.03294032e-05,  8.91690606e-03,  9.64222991e-03,\n",
              "           1.45441841e-02,  1.08768757e-02,  1.01184069e-02,\n",
              "           3.05675080e-07,  1.71905352e-03,  2.87682272e-05,\n",
              "           1.46022913e-02,  1.45960663e-02,  5.03078848e-03,\n",
              "           3.99597462e-04,  1.98940126e-04,  1.45786020e-02,\n",
              "           1.45556756e-02],\n",
              "         [ 4.81434796e-02,  1.78701122e-03,  1.80987651e-06,\n",
              "           4.75503382e-08,  4.81276174e-02,  9.40847413e-07,\n",
              "           5.56464773e-04,  4.73948258e-02,  4.73516086e-02,\n",
              "           4.71196523e-02,  9.96942300e-05,  2.25025339e-05,\n",
              "           1.38198625e-02,  4.13939345e-02,  1.76127466e-02,\n",
              "           1.50079684e-04,  2.81020762e-11,  4.81297176e-02,\n",
              "           2.27915307e-04,  1.27591870e-05,  4.81529076e-02,\n",
              "           4.81535815e-02,  4.81542899e-02,  4.68942073e-02,\n",
              "           5.84157109e-06,  3.57362914e-04,  5.90616822e-04,\n",
              "           4.32067194e-02,  4.80185646e-02,  4.80414063e-02,\n",
              "           4.81212096e-02,  4.81486330e-02,  4.81161710e-02,\n",
              "           4.63768072e-02,  4.74291461e-02,  8.92470807e-06,\n",
              "           4.81525775e-02,  2.61080563e-05,  1.51726853e-06,\n",
              "           3.69259669e-05,  4.68318058e-02,  2.63315324e-05,\n",
              "           1.10514879e-03,  4.78684780e-02,  4.79658260e-02,\n",
              "           1.07724191e-03,  1.57057853e-07,  1.45046082e-07,\n",
              "           2.31927674e-04,  2.94055855e-02,  3.17975107e-02,\n",
              "           4.79628524e-02,  3.58690444e-02,  3.33678160e-02,\n",
              "           1.00803515e-06,  5.66898148e-03,  9.48699648e-05,\n",
              "           4.81544743e-02,  4.81339461e-02,  1.65902029e-02,\n",
              "           1.31776619e-03,  6.56051644e-04,  4.80763535e-02,\n",
              "           4.80007483e-02],\n",
              "         [ 6.39722367e-05,  2.37455011e-06,  2.40493312e-09,\n",
              "           6.31840804e-11,  6.39511592e-05,  1.25018204e-09,\n",
              "           7.39420923e-07,  6.29774382e-05,  6.29200119e-05,\n",
              "           6.26117923e-05,  1.32471997e-07,  2.99009842e-08,\n",
              "           1.83635982e-05,  5.50035559e-05,  2.34035180e-05,\n",
              "           1.99423331e-07,  3.73415607e-14,  6.39539500e-05,\n",
              "           3.02849983e-07,  1.69541907e-08,  6.39847644e-05,\n",
              "           6.39856598e-05,  6.39866011e-05,  6.23122248e-05,\n",
              "           7.76218028e-09,  4.74857760e-07,  7.84801585e-07,\n",
              "           5.74123537e-05,  6.38062518e-05,  6.38366034e-05,\n",
              "           6.39426446e-05,  6.39790844e-05,  6.39359494e-05,\n",
              "           6.16247123e-05,  6.30230424e-05,  1.18590002e-08,\n",
              "           6.39843258e-05,  3.46919411e-08,  2.01612062e-09,\n",
              "           4.90665966e-08,  6.22293068e-05,  3.49888923e-08,\n",
              "           1.46850291e-06,  6.36068192e-05,  6.37361736e-05,\n",
              "           1.43142072e-06,  2.08695802e-10,  1.92734766e-10,\n",
              "           3.08181547e-07,  3.90736417e-05,  4.22519912e-05,\n",
              "           6.37322223e-05,  4.76621760e-05,  4.43385861e-05,\n",
              "           1.33945995e-09,  7.53284614e-06,  1.26061595e-07,\n",
              "           6.39868462e-05,  6.39595687e-05,  2.20447793e-05,\n",
              "           1.75102530e-06,  8.71750263e-07,  6.38830406e-05,\n",
              "           6.37825777e-05],\n",
              "         [ 5.03061637e-03,  1.86728670e-04,  1.89117913e-07,\n",
              "           4.96863773e-09,  5.02895889e-03,  9.83111822e-08,\n",
              "           5.81462083e-05,  4.95238791e-03,  4.94787205e-03,\n",
              "           4.92363443e-03,  1.04172658e-05,  2.35133846e-06,\n",
              "           1.44406734e-03,  4.32534179e-03,  1.84039401e-03,\n",
              "           1.56821509e-05,  2.93644675e-12,  5.02917835e-03,\n",
              "           2.38153637e-05,  1.33323506e-06,  5.03160152e-03,\n",
              "           5.03167193e-03,  5.03174595e-03,  4.90007720e-03,\n",
              "           6.10398404e-07,  3.73416242e-05,  6.17148298e-05,\n",
              "           4.51476361e-03,  5.01756373e-03,  5.01995051e-03,\n",
              "           5.02828932e-03,  5.03115486e-03,  5.02776283e-03,\n",
              "           4.84601294e-03,  4.95597411e-03,  9.32562059e-07,\n",
              "           5.03156703e-03,  2.72808730e-06,  1.58542673e-07,\n",
              "           3.85847419e-06,  4.89355673e-03,  2.75143880e-06,\n",
              "           1.15479389e-04,  5.00188086e-03,  5.01205296e-03,\n",
              "           1.12563338e-04,  1.64113149e-08,  1.51561790e-08,\n",
              "           2.42346245e-05,  3.07265326e-03,  3.32259070e-03,\n",
              "           5.01174224e-03,  3.74803407e-03,  3.48667530e-03,\n",
              "           1.05331774e-07,  5.92364142e-04,  9.91316792e-06,\n",
              "           5.03176523e-03,  5.02962019e-03,  1.73354620e-03,\n",
              "           1.37696241e-04,  6.85522560e-05,  5.02360221e-03,\n",
              "           5.01570207e-03],\n",
              "         [-2.26172963e-03, -8.39518928e-05, -8.50260798e-08,\n",
              "          -2.23386448e-09, -2.26098444e-03, -4.42000140e-08,\n",
              "          -2.61421251e-05, -2.22655867e-03, -2.22452837e-03,\n",
              "          -2.21363131e-03, -4.68352923e-06, -1.05714519e-06,\n",
              "          -6.49242490e-04, -1.94464316e-03, -8.27428163e-04,\n",
              "          -7.05058444e-06, -1.32020575e-12, -2.26108311e-03,\n",
              "          -1.07072195e-05, -5.99413081e-07, -2.26217255e-03,\n",
              "          -2.26220421e-03, -2.26223749e-03, -2.20304014e-03,\n",
              "          -2.74430817e-07, -1.67885308e-05, -2.77465522e-05,\n",
              "          -2.02980587e-03, -2.25586126e-03, -2.25693434e-03,\n",
              "          -2.26068341e-03, -2.26197174e-03, -2.26044670e-03,\n",
              "          -2.17873323e-03, -2.22817100e-03, -4.19273324e-07,\n",
              "          -2.26215704e-03, -1.22652881e-06, -7.12796672e-08,\n",
              "          -1.73474278e-06, -2.20010859e-03, -1.23702748e-06,\n",
              "          -5.19187185e-05, -2.24881035e-03, -2.25338365e-03,\n",
              "          -5.06076828e-05, -7.37841141e-09, -6.81411116e-09,\n",
              "          -1.08957162e-05, -1.38144323e-03, -1.49381334e-03,\n",
              "          -2.25324396e-03, -1.68508968e-03, -1.56758462e-03,\n",
              "          -4.73564224e-08, -2.66322740e-04, -4.45689037e-06,\n",
              "          -2.26224615e-03, -2.26128176e-03, -7.79390144e-04,\n",
              "          -6.19072586e-05, -3.08206107e-05, -2.25857612e-03,\n",
              "          -2.25502427e-03],\n",
              "         [ 6.46735829e-05,  2.40058300e-06,  2.43129910e-09,\n",
              "           6.38767859e-11,  6.46522744e-05,  1.26388815e-09,\n",
              "           7.47527410e-07,  6.36678782e-05,  6.36098223e-05,\n",
              "           6.32982236e-05,  1.33924326e-07,  3.02287974e-08,\n",
              "           1.85649237e-05,  5.56065759e-05,  2.36600976e-05,\n",
              "           2.01609667e-07,  3.77509471e-14,  6.46550958e-05,\n",
              "           3.06170215e-07,  1.71400644e-08,  6.46862480e-05,\n",
              "           6.46871533e-05,  6.46881049e-05,  6.29953719e-05,\n",
              "           7.84727932e-09,  4.80063764e-07,  7.93405594e-07,\n",
              "           5.80417821e-05,  6.45057783e-05,  6.45364627e-05,\n",
              "           6.46436664e-05,  6.46805058e-05,  6.46368979e-05,\n",
              "           6.23003220e-05,  6.37139824e-05,  1.19890139e-08,\n",
              "           6.46858046e-05,  3.50722789e-08,  2.03822393e-09,\n",
              "           4.96045280e-08,  6.29115448e-05,  3.53724857e-08,\n",
              "           1.48460254e-06,  6.43041593e-05,  6.44349318e-05,\n",
              "           1.44711380e-06,  2.10983795e-10,  1.94847774e-10,\n",
              "           3.11560231e-07,  3.95020174e-05,  4.27152121e-05,\n",
              "           6.44309372e-05,  4.81847103e-05,  4.48246830e-05,\n",
              "           1.35414484e-09,  7.61543092e-06,  1.27443645e-07,\n",
              "           6.46883527e-05,  6.46607761e-05,  2.22864627e-05,\n",
              "           1.77022230e-06,  8.81307516e-07,  6.45834090e-05,\n",
              "           6.44818447e-05],\n",
              "         [ 4.87728060e-03,  1.81037084e-04,  1.83353502e-07,\n",
              "           4.81719111e-09,  4.87567364e-03,  9.53146069e-08,\n",
              "           5.63738821e-05,  4.80143659e-03,  4.79705837e-03,\n",
              "           4.77355953e-03,  1.00997422e-05,  2.27966846e-06,\n",
              "           1.40005143e-03,  4.19350316e-03,  1.78429785e-03,\n",
              "           1.52041509e-05,  2.84694235e-12,  4.87588641e-03,\n",
              "           2.30894592e-05,  1.29259738e-06,  4.87823572e-03,\n",
              "           4.87830399e-03,  4.87837576e-03,  4.75072033e-03,\n",
              "           5.91793147e-07,  3.62034323e-05,  5.98337302e-05,\n",
              "           4.37715130e-03,  4.86462582e-03,  4.86693984e-03,\n",
              "           4.87502448e-03,  4.87780268e-03,  4.87451404e-03,\n",
              "           4.69830398e-03,  4.80491348e-03,  9.04137090e-07,\n",
              "           4.87820229e-03,  2.64493380e-06,  1.53710211e-07,\n",
              "           3.74086592e-06,  4.74439861e-03,  2.66757354e-06,\n",
              "           1.11959518e-04,  4.84942096e-03,  4.85928301e-03,\n",
              "           1.09132350e-04,  1.59110896e-08,  1.46942109e-08,\n",
              "           2.34959407e-05,  2.97899721e-03,  3.22131643e-03,\n",
              "           4.85898176e-03,  3.63379207e-03,  3.38039964e-03,\n",
              "           1.02121207e-07,  5.74308579e-04,  9.61100948e-06,\n",
              "           4.87839444e-03,  4.87631479e-03,  1.68070682e-03,\n",
              "           1.33499189e-04,  6.64627481e-05,  4.87048024e-03,\n",
              "           4.86282090e-03],\n",
              "         [ 1.07435554e-01,  3.98784098e-03,  4.03886648e-06,\n",
              "           1.06111917e-07,  1.07400156e-01,  2.09956704e-06,\n",
              "           1.24179020e-03,  1.05764881e-01,  1.05668438e-01,\n",
              "           1.05150811e-01,  2.22474672e-04,  5.02159839e-05,\n",
              "           3.08399933e-02,  9.23734704e-02,  3.93040803e-02,\n",
              "           3.34913349e-04,  6.27117555e-11,  1.07404843e-01,\n",
              "           5.08609006e-04,  2.84730215e-05,  1.07456593e-01,\n",
              "           1.07458097e-01,  1.07459678e-01,  1.04647715e-01,\n",
              "           1.30358759e-05,  7.97480427e-04,  1.31800290e-03,\n",
              "           9.64188272e-02,  1.07156798e-01,  1.07207770e-01,\n",
              "           1.07385857e-01,  1.07447054e-01,  1.07374613e-01,\n",
              "           1.03493101e-01,  1.05841469e-01,  1.99161125e-05,\n",
              "           1.07455857e-01,  5.82619603e-05,  3.38589124e-06,\n",
              "           8.24028871e-05,  1.04508462e-01,  5.87606628e-05,\n",
              "           2.46621710e-03,  1.06821869e-01,  1.07039108e-01,\n",
              "           2.40394093e-03,  3.50485622e-07,  3.23680513e-07,\n",
              "           5.17562883e-04,  6.56206281e-02,  7.09583771e-02,\n",
              "           1.07032472e-01,  8.00442903e-02,  7.44626235e-02,\n",
              "           2.24950118e-06,  1.26507301e-02,  2.11708986e-04,\n",
              "           1.07460090e-01,  1.07414279e-01,  3.70222023e-02,\n",
              "           2.94068775e-03,  1.46402529e-03,  1.07285757e-01,\n",
              "           1.07117039e-01],\n",
              "         [ 1.14695799e-01,  4.25732999e-03,  4.31180367e-06,\n",
              "           1.13282714e-07,  1.14658009e-01,  2.24145090e-06,\n",
              "           1.32570749e-03,  1.12912225e-01,  1.12809265e-01,\n",
              "           1.12256659e-01,  2.37508993e-04,  5.36094632e-05,\n",
              "           3.29240882e-02,  9.86158545e-02,  4.19601586e-02,\n",
              "           3.57546014e-04,  6.69496700e-11,  1.14663013e-01,\n",
              "           5.42979619e-04,  3.03971620e-05,  1.14718260e-01,\n",
              "           1.14719865e-01,  1.14721553e-01,  1.11719564e-01,\n",
              "           1.39168101e-05,  8.51372298e-04,  1.40707046e-03,\n",
              "           1.02934587e-01,  1.14398205e-01,  1.14452622e-01,\n",
              "           1.14642743e-01,  1.14708076e-01,  1.14630739e-01,\n",
              "           1.10486923e-01,  1.12993989e-01,  2.12619970e-05,\n",
              "           1.14717473e-01,  6.21991679e-05,  3.61470189e-06,\n",
              "           8.79714824e-05,  1.11570900e-01,  6.27315717e-05,\n",
              "           2.63287831e-03,  1.14040642e-01,  1.14272561e-01,\n",
              "           2.56639366e-03,  3.74170625e-07,  3.45554089e-07,\n",
              "           5.52538578e-04,  7.00551174e-02,  7.57535790e-02,\n",
              "           1.14265477e-01,  8.54534972e-02,  7.94946343e-02,\n",
              "           2.40151724e-06,  1.35056370e-02,  2.26015786e-04,\n",
              "           1.14721992e-01,  1.14673086e-01,  3.95240765e-02,\n",
              "           3.13941259e-03,  1.56296072e-03,  1.14535879e-01,\n",
              "           1.14355759e-01]])])"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# stop_zone 3\n",
        "net=Network([784,128,64,10])\n",
        "net.backpropagation(train_X[0],train_y[0])\n",
        "\n",
        "# Desired output : (10,1) (10,64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "9pq4E3rHik-f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(128, 1)\n",
            "(64, 1)\n",
            "(10, 1)\n",
            "(128, 784)\n",
            "(64, 128)\n",
            "(10, 64)\n"
          ]
        }
      ],
      "source": [
        "# stop_zone 4\n",
        "net=Network([784,128,64,10])\n",
        "nabla_b,nabla_w=net.backpropagation(train_X[0],train_y[0])\n",
        "for nb in nabla_b:\n",
        "  print(nb.shape)\n",
        "for nw in nabla_w:\n",
        "  print(nw.shape)\n",
        "\n",
        "# Desired output:\n",
        "# (128, 1)\n",
        "# (64, 1)\n",
        "# (10, 1)\n",
        "# (128, 784)\n",
        "# (64, 128)\n",
        "# (10, 64)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "FaCblO7XE0Fy"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Tejas\\AppData\\Local\\Temp\\ipykernel_22996\\2813754479.py:104: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  num = sum(int(x == y) for x, y in test_results)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1722/10000 classified correctly.\n",
            "Epoch 1 completed.\n",
            "1885/10000 classified correctly.\n",
            "Epoch 2 completed.\n",
            "2044/10000 classified correctly.\n",
            "Epoch 3 completed.\n",
            "2197/10000 classified correctly.\n",
            "Epoch 4 completed.\n",
            "2345/10000 classified correctly.\n",
            "Epoch 5 completed.\n",
            "2472/10000 classified correctly.\n",
            "Epoch 6 completed.\n",
            "2572/10000 classified correctly.\n",
            "Epoch 7 completed.\n",
            "2676/10000 classified correctly.\n",
            "Epoch 8 completed.\n",
            "2781/10000 classified correctly.\n",
            "Epoch 9 completed.\n",
            "2866/10000 classified correctly.\n",
            "Epoch 10 completed.\n",
            "2931/10000 classified correctly.\n",
            "Epoch 11 completed.\n",
            "3009/10000 classified correctly.\n",
            "Epoch 12 completed.\n",
            "3076/10000 classified correctly.\n",
            "Epoch 13 completed.\n",
            "3131/10000 classified correctly.\n",
            "Epoch 14 completed.\n",
            "3197/10000 classified correctly.\n",
            "Epoch 15 completed.\n",
            "3261/10000 classified correctly.\n",
            "Epoch 16 completed.\n",
            "3315/10000 classified correctly.\n",
            "Epoch 17 completed.\n",
            "3362/10000 classified correctly.\n",
            "Epoch 18 completed.\n",
            "3412/10000 classified correctly.\n",
            "Epoch 19 completed.\n",
            "3472/10000 classified correctly.\n",
            "Epoch 20 completed.\n"
          ]
        }
      ],
      "source": [
        "# Stop zone 5 :  Run this cell, for 10000 samples and batch size of 20, output should be\n",
        "#       (500,20,2).  500 batches each of size 20 and has 2 objects : train and test data.\n",
        "\n",
        "net=Network([784,256,128,64,10])\n",
        "net.SGD(train_data=train_data,epochs=20,mini_batch_size=20,lr=0.01)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXljiAYRlvdq"
      },
      "outputs": [],
      "source": [
        "net=Network([784,128,64,10])\n",
        "net.SGD(train_data=train_data,epochs=10,mini_batch_size=20,lr=0.01)\n",
        "print(\"Test data:\")\n",
        "net.predict(test_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhMIoFT9m7OU"
      },
      "source": [
        "# End of question 1"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
